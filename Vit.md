| Model Name                                                          | Year | Reference                 |
| ------------------------------------------------------------------- | ---- | ------------------------- |
| ViT (Vision Transformer)                                            | 2020 | Dosovitskiy et al. (2021) |
| DeiT (Data-efficient image Transformers)                            | 2021 | Touvron et al. (2021)     |
| PVT (Pyramid Vision Transformer)                                    | 2021 | Wang et al. (2021)        |
| TNT (Transformer-iN-Transformer)                                    | 2021 | Han et al. (2021)         |
| Swin (Swin Transformer)                                             | 2021 | Liu et al. (2021)         |
| CSWin (Cross-Shaped Window Transformer)                             | 2022 | Dong et al. (2022)        |
| IPT (Image Processing Transformer)                                  | 2020 | Chen et al. (2020)        |
| SETR (SEgmentation TRansformer)                                     | 2020 | Zheng et al. (2020)       |
| CLIP (Contrastive Language-Image Pre-training)                      | 2020 | Radford et al. (2020)     |
| CvT (Convolutional Vision Transformer)                              | 2021 | Wu et al. (2021)          |
| VT (Visual Transformer)                                             | 2020 | Wu et al. (2020)          |
| PiT (Pyramidal Image Transformer)                                   | 2021 | Heo et al. (2021)         |
| CoT (Convolutional Transformer)                                     | 2021 | Li et al. (2021)          |
| CPVT (Convolutional Pyramid Vision Transformer)                     | 2021 | Niu et al. (2021)         |
| SegFormer (Segmentation Transformer)                                | 2021 | Xie et al. (2021)         |
| Twins (Twins: Re-purposing Pre-trained Models for Object Detection) | 2021 | Chu et al. (2021)         |
| Swin-BERT (Swin Transformer with BERT)                              | 2021 | Wang et al. (2021)        |
| ViL (Vision-and-Language Transformer)                               | 2021 | Kim et al. (2021)         |
| ViLBERT (Vision-and-Language BERT)                                  | 2020 | Lu et al. (2020)          |
| LViT (Lightweight Vision Transformer)                               | 2021 | Li et al. (2021)          |
| MobileViT (Mobile Vision Transformer)                               | 2021 | Mehta et al. (2021)       |
| T2T-ViT (Tokens-to-Token Vision Transformer)                        | 2021 | Yuan et al. (2021)        |
| CaiT (Class-Attention in Image Transformers)                        | 2021 | Touvron et al. (2021)     |
| XCiT (Cross-Covariance Image Transformers)                          | 2021 | Ali et al. (2021)         |
| Co-Tuning (Co-Tuning of Vision Transformers)                        | 2021 | Wang et al. (2021)        |
| DVT (Dense Vision Transformer)                                      | 2021 | Li et al. (2021)          |
| FNet (Fourier Neural Transformer)                                   | 2021 | Lee-Thorp et al. (2021)   |
| GPViT (Gaussian Process Vision Transformer)                         | 2021 | Wang et al. (2021)        |
| HiT (Hierarchical Transformer)                                      | 2021 | Chen et al. (2021)        |
| iBOT (Image-based Object Transformers)                              | 2021 | Wang et al. (2021)        |
| LeViT (Lightweight Vision Transformer)                              | 2021 | Graham et al. (2021)      |
| MViT (Multiscale Vision Transformer)                                | 2021 | Li et al. (2021)          |
| NesT (Neural Sparse Transformer)                                    | 2021 | Wang et al. (2021)        |
| PVTv2 (Pyramid Vision Transformer v2)                               | 2021 | Wang et al. (2021)        |
| RegionViT (Region-based Vision Transformer)                         | 2021 | Chen et al. (2021)        |
| SPT (Sparse Transformer)                                            | 2021 | Wang et al. (2021)        |
| T5-ViT (T5-based Vision Transformer)                                | 2021 | Wang et al. (2021)        |
| TokenLabel (Token-level Labeling for Vision Transformers)           | 2021 | Wang et al. (2021)        |
| TransGAN (Transformer-based Generative Adversarial Networks)        | 2021 | Jiang et al. (2021)       |
| UiT (Unified Image Transformer)                                     | 2021 | Li et al. (2021)          |
| Volo (Vision-Language Transformer)                                  | 2021 | Wang et al. (2021)        |

| #   | Vision Transformer Model                                                  | Description                                                                     |
| --- | ------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |
| 1   | ViT (Vision Transformer)                                                  | Original Vision Transformer model                                               |
| 2   | DeiT (Data-efficient Image Transformers)                                  | Efficient training of transformers with distillation                            |
| 3   | Swin Transformer (Shifted Window Transformer)                             | Hierarchical transformer using shifted windows                                  |
| 4   | T2T-ViT (Tokens-to-Token Vision Transformer)                              | Training transformers from scratch on ImageNet                                  |
| 5   | PVT (Pyramid Vision Transformer)                                          | Versatile backbone for dense prediction without convolutions                    |
| 6   | CvT (Convolutional Vision Transformer)                                    | Introducing convolutions to vision transformers                                 |
| 7   | CrossViT (Cross Attention Vision Transformer)                             | Multi-scale vision transformer for image classification                         |
| 8   | PiT (Pooling-based Vision Transformer)                                    | Rethinking spatial dimensions of vision transformers                            |
| 9   | Twins                                                                     | Revisiting the design of spatial attention in vision transformers               |
| 10  | ViTAE (Vision Transformer Advanced by Exploring Intrinsic Inductive Bias) | Exploring intrinsic inductive bias                                              |
| 11  | CaiT (Class-Attention in Image Transformers)                              | Going deeper with image transformers                                            |
| 12  | LeViT (Leaner Vision Transformer)                                         | A vision transformer in ConvNet's clothing for faster inference                 |
| 13  | MLP-Mixer                                                                 | An all-MLP architecture for vision                                              |
| 14  | EfficientViT                                                              | Improving the efficiency of vision transformers                                 |
| 15  | Beit (Bidirectional Encoder representation from Image Transformers)       | BERT pre-training of image transformers                                         |
| 16  | SwinV2 (Swin Transformer V2)                                              | An improved version of Swin Transformer                                         |
| 17  | ConvMixer                                                                 | Combining convolutions and MLP-mixers                                           |
| 18  | Focal Transformer                                                         | Integrating focal attention mechanisms                                          |
| 19  | CoAtNet                                                                   | Combining convolution and attention for visual recognition                      |
| 20  | MobileViT                                                                 | Mobile-friendly vision transformers                                             |
| 21  | VOLO (Vision Outlooker)                                                   | Vision transformer with outlook attention                                       |
| 22  | DPT (Dense Prediction Transformer)                                        | Dense prediction with transformers                                              |
| 23  | XCiT (Cross-Covariance Image Transformers)                                | Transformers with cross-covariance attention                                    |
| 24  | Segmenter                                                                 | Transformer for semantic segmentation                                           |
| 25  | MaxViT                                                                    | Transformers with max pooling                                                   |
| 26  | SEViT (Scale-Equivariant Vision Transformer)                              | Scale-equivariant attention in vision transformers                              |
| 27  | ViT-G (Vision Transformer - Global)                                       | Global vision transformer model                                                 |
| 28  | NesT (Nested Transformers)                                                | Hierarchical transformers with nested structure                                 |
| 29  | MAE (Masked Autoencoders)                                                 | Self-supervised learning with masked autoencoders                               |
| 30  | VIT-VQGAN                                                                 | Combining VQGAN and Vision Transformer for image synthesis                      |
| 31  | AST (Audio Spectrogram Transformer)                                       | Vision transformers applied to audio spectrograms                               |
| 32  | DAT (Deformable Attention Transformer)                                    | Deformable attention mechanisms for vision transformers                         |
| 33  | RegionViT                                                                 | Region-based vision transformers                                                |
| 34  | Twin-SVT                                                                  | Twin-transformers with shared vision tasks                                      |
| 35  | Perceiver IO                                                              | Unified architecture for processing different input modalities including images |
| 36  | HAT (Hierarchical Attention Transformer)                                  | Hierarchical vision transformers                                                |
| 37  | Dilated Transformer                                                       | Vision transformers with dilated attention                                      |
| 38  | GLiT (Global-Local Image Transformer)                                     | Combining global and local attention in vision transformers                     |
| 39  | HViT (Hybrid Vision Transformer)                                          | Hybrid architecture combining CNNs and transformers                             |
| 40  | OmniNet                                                                   | Omnidirectional attention mechanisms in vision transformers                     |
